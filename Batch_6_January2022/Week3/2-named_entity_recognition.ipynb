{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is a shorter version of the token classification notebook prepared by Huggingface.\n",
    "\n",
    "Some parts are intentionally removed, to make this notebook easier, for educational purposes.\n",
    "\n",
    "Source of the original notebook:\n",
    "\n",
    "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb#scrollTo=545PP3o8IrJV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Token Classification\n",
    "\n",
    "Token classification is about classifying the parts (words, subwords...) of a text.\n",
    "\n",
    "Most known application is Named Entity Recognition:\n",
    "- [ \"My\", \"name\", \"is\", \"Ahmet\", \".\" ]\n",
    "- [ \"O\", \"O\", \"O\", \"PERSON\", \"O\" ]\n",
    "\n",
    "Named entity recognition finds the special entities in a text, such as \"person\", \"location\", \"date\".\n",
    "\n",
    "It is a type of token classification, classes being \"O\", \"PERSON\", \"LOC\", \"DATE\".\n",
    "\n",
    "Here is an another example with a drawing:\n",
    "\n",
    "![](ner.drawio.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration for Named Entity Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (1.14.0)\r\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (4.11.3)\r\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (5.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (0.3.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (2.26.0)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (1.3.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (4.62.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (1.19.5)\r\n",
      "Requirement already satisfied: aiohttp in /home/gsoykan20/.local/lib/python3.8/site-packages (from datasets) (3.7.4.post0)\r\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (21.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (2021.8.1)\r\n",
      "Collecting huggingface-hub<0.1.0,>=0.0.19\r\n",
      "  Using cached huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\r\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from datasets) (0.70.12.2)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.10.0.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (5.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.6)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.2)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.5)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from transformers) (2021.8.28)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from transformers) (0.0.46)\r\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/gsoykan20/.local/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gsoykan20/.local/lib/python3.8/site-packages (from aiohttp->datasets) (5.1.0)\r\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gsoykan20/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.6.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from pandas->datasets) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\r\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\r\n",
      "Installing collected packages: huggingface-hub\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.4.0\r\n",
      "    Uninstalling huggingface-hub-0.4.0:\r\n",
      "      Successfully uninstalled huggingface-hub-0.4.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spacy-transformers 1.0.6 requires transformers<4.10.0,>=3.4.0, but you have transformers 4.11.3 which is incompatible.\u001B[0m\r\n",
      "Successfully installed huggingface-hub-0.0.19\r\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "049c59e5d6f34bcd89de74c6a4e42fef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d4b43dc041441a7a7ae90dd18c06841"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset conllpp/conllpp (download: 4.63 MiB, generated: 9.78 MiB, post-processed: Unknown size, total: 14.41 MiB) to /home/gsoykan20/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1957673e2bc4402907ddfee7b39b781"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/650k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15643070d695420fad648e4d806ecf64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/163k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1ab7cbe6a224b4294232c8f696f5b1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/141k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4d1784589ed425a9a9b6f1f6e359381"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f52a2831f43f41688297f71889feeff6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51033e5949ce4e4dbcb075b268691ad7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1443bb67360a450dacf359e6604c821c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b924c6925fd24ba39acc902964a3e332"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conllpp downloaded and prepared to /home/gsoykan20/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "268c084d7cfc4ca2ac00329c04353857"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token classification\n",
    "# named entity recognition NER\n",
    "# part of speech tagging POS\n",
    "\n",
    "# distillation learning\n",
    "\n",
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16\n",
    "\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"conllpp\")\n",
    "\n",
    "datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '0',\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.']}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
    "print(label_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show random elements from dataset to understand it better"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    dataset_len = len(dataset)\n",
    "    assert num_examples <= dataset_len, \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = random.sample(range(dataset_len), num_examples)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tokens</th>\n      <th>pos_tags</th>\n      <th>chunk_tags</th>\n      <th>ner_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11034</td>\n      <td>[The, present, noise, levels, have, applied, at, Heathrow, ,, one, of, the, world, 's, busiest, airports, ,, since, 1959, and, at, Gatwick, since, 1968, .]</td>\n      <td>[DT, JJ, NN, NNS, VBP, VBN, IN, NNP, ,, CD, IN, DT, NN, POS, JJS, NNS, ,, IN, CD, CC, IN, NNP, IN, CD, .]</td>\n      <td>[B-NP, I-NP, I-NP, I-NP, B-VP, I-VP, B-PP, B-NP, O, B-NP, B-PP, B-NP, I-NP, B-NP, I-NP, I-NP, O, B-PP, B-NP, O, B-PP, B-NP, B-PP, B-NP, O]</td>\n      <td>[O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3855</td>\n      <td>[EASTERN, DIVISION]</td>\n      <td>[NNP, NNP]</td>\n      <td>[B-NP, I-NP]</td>\n      <td>[B-MISC, I-MISC]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1905</td>\n      <td>[Portsmouth, 1, Queens, Park, Rangers, 2]</td>\n      <td>[NNP, CD, NNP, NNP, NNPS, CD]</td>\n      <td>[B-NP, I-NP, I-NP, I-NP, I-NP, I-NP]</td>\n      <td>[B-ORG, O, B-ORG, I-ORG, I-ORG, O]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6577</td>\n      <td>[Although, Danny, Rose, 's, 50th-minute, equaliser, gave, the, Seychellois, renewed, hope, they, could, not, find, the, net, again, and, were, eliminated, .]</td>\n      <td>[IN, NNP, NNP, POS, JJ, NN, VBD, DT, NNP, VBD, NN, PRP, MD, RB, VB, DT, JJ, RB, CC, VBD, VBN, .]</td>\n      <td>[B-SBAR, B-NP, I-NP, B-NP, I-NP, I-NP, B-VP, B-NP, I-NP, B-VP, B-NP, B-NP, B-VP, I-VP, I-VP, B-NP, I-NP, B-ADVP, O, B-VP, I-VP, O]</td>\n      <td>[O, B-PER, I-PER, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13075</td>\n      <td>[USDA, gross, cutout, hide, and, offal, value, .]</td>\n      <td>[NNP, JJ, JJ, NN, CC, NN, NN, .]</td>\n      <td>[B-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, O]</td>\n      <td>[B-ORG, O, O, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10019</td>\n      <td>[Martin, Gates, ,, Anders, Haglund, (, Sweden, )]</td>\n      <td>[NNP, NNP, ,, NNP, NNP, (, NNP, )]</td>\n      <td>[B-NP, I-NP, O, B-NP, I-NP, O, B-NP, O]</td>\n      <td>[B-PER, I-PER, O, B-PER, I-PER, O, B-LOC, O]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1020</td>\n      <td>[The, HCFA, Administrator, reversed, a, previously, favorable, decision, regarding, the, reimbursement, of, costs, related, to, the, company, 's, community, liaison, personnel, ,, it, added, .]</td>\n      <td>[DT, NNP, NNP, VBD, DT, RB, JJ, NN, VBG, DT, NN, IN, NNS, VBN, TO, DT, NN, POS, NN, NN, NNS, ,, PRP, VBD, .]</td>\n      <td>[B-NP, I-NP, I-NP, B-VP, B-NP, I-NP, I-NP, I-NP, B-VP, B-NP, I-NP, B-PP, B-NP, B-VP, B-PP, B-NP, I-NP, B-NP, I-NP, I-NP, I-NP, O, B-NP, B-VP, O]</td>\n      <td>[O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3600</td>\n      <td>[Worcestershire, 205-9, (, K., Spiring, 52, ), .]</td>\n      <td>[NNP, CD, (, NNP, NNP, CD, ), .]</td>\n      <td>[B-NP, I-NP, O, B-NP, I-NP, I-NP, O, O]</td>\n      <td>[B-ORG, O, O, B-PER, I-PER, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8380</td>\n      <td>[SQUASH, -, HONG, KONG, OPEN, FIRST, ROUND, RESULTS, .]</td>\n      <td>[NNP, :, NNP, NNP, NNP, NNP, NNP, NNS, .]</td>\n      <td>[B-NP, O, B-NP, I-NP, O, B-NP, I-NP, I-NP, O]</td>\n      <td>[O, O, B-MISC, I-MISC, I-MISC, O, O, O, O]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8195</td>\n      <td>[Birmingham, 2, 1, 1, 0, 5, 4, 4]</td>\n      <td>[NNP, CD, CD, CD, CD, CD, CD, CD]</td>\n      <td>[B-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP]</td>\n      <td>[B-ORG, O, O, O, O, O, O, O]</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing for Named Entity Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4cee7eb939446538f16d17e8e2374e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [101, 7592, 1010, 2023, 2003, 2028, 6251, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what tokenizer does\n",
    "tokenizer(\"Hello, this is one sentence!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What is subword tokenization?\n",
    "\n",
    "Subtokens are used in modern approaches in lieu of stemming and lemmatization.\n",
    "\n",
    "Since it is hard to represent every possible state of a word, like:\n",
    "- head -> token id: 1\n",
    "- hunt -> token id: 2\n",
    "- hunter -> token id: 3\n",
    "- headhunter -> token id: 4\n",
    "\n",
    "We instead do this:\n",
    "- head -> token id: 1\n",
    "- hunt -> token id: 2\n",
    "- -er -> token id: 3\n",
    "- headhunter -> token ids: 1 2 3\n",
    "\n",
    "This way, it is easier to represent compound words and words with additions. Especially in Turkish language, additions of a word is a huge issue.\n",
    "\n",
    "Techniques like Byte-Pair-Encoding is also utilized when we want to be language agnostic, and learn our tokens from data, in an unsupervised way."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][4]\n",
    "print(example[\"tokens\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'germany', \"'\", 's', 'representative', 'to', 'the', 'european', 'union', \"'\", 's', 'veterinary', 'committee', 'werner', 'z', '##wing', '##mann', 'said', 'on', 'wednesday', 'consumers', 'should', 'buy', 'sheep', '##me', '##at', 'from', 'countries', 'other', 'than', 'britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "However, we do not have three labels for each subword token of Zwingmann, like:\n",
    "\n",
    "`Z -> [PER] ##wing -> [PER] ##mann -> [PER]`\n",
    "\n",
    "(\"##\" is used when we want to sign that the string is not an original word, instead, it is a non-first subword of an original word.)\n",
    "\n",
    "Instead, we have only one label for the whole word:\n",
    "\n",
    "`Zwingmann -> [PER]`\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())\n",
    "print(len(tokenized_input[\"input_ids\"]) == len(tokenized_input.word_ids()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aligning subwords with word labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're now ready to write the function that will preprocess our samples.\n",
    "- We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model)\n",
    "- and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "#If you wonder what `label_all_tokens` is, go to original notebook, cited at the top of this notebook.\n",
    "# It is intentionally removed to reduce the complexity of the notebook.\n",
    "label_all_tokens = True\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"],\n",
    "                                 truncation=True,\n",
    "                                 is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "             # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], [101, 2848, 13934, 102], [101, 9371, 2727, 1011, 5511, 1011, 2570, 102], [101, 1996, 2647, 3222, 2056, 2006, 9432, 2009, 18335, 2007, 2446, 6040, 2000, 10390, 2000, 18454, 2078, 2329, 12559, 2127, 6529, 5646, 3251, 5506, 11190, 4295, 2064, 2022, 11860, 2000, 8351, 1012, 102], [101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100], [-100, 1, 2, -100], [-100, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_align_labels(datasets['train'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/15 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b97b4d933f2542aaaae961b3ce8f74fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ada62f75fc04a18a5e8785282ed63d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad13b1dda8894f6eb6cb82c2e812703f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning the NER model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-{task}\",\n",
    "    evaluation_strategy = IntervalStrategy.EPOCH,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting seqeval\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 43 kB 865 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from seqeval) (1.19.5)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from seqeval) (0.24.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/envs/lit_template/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.2)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=c3671f43dcfd833b980f03cb54a25ffbb39976f42ef3f0f2dc47da4c04406f13\r\n",
      "  Stored in directory: /home/gsoykan20/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n"
     ]
    }
   ],
   "source": [
    "# seqeval is a Python framework for sequence labeling evaluation. seqeval can evaluate the performance of chunking tasks such as named-entity recognition, part-of-speech tagging, semantic role labeling and so on.\n",
    "!pip install seqeval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.48k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c510e10eaa14858a5dded2fa678636d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This metric takes list of labels for the predictions and references:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "{'LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[f\"{task}_tags\"]]\n",
    "# testing the metric\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we will need to do a bit of post-processing on our predictions:\n",
    "- select the predicted index (with the maximum logit) for each token\n",
    "- convert it to its string label\n",
    "- ignore everywhere we set a label of -100\n",
    "\n",
    "The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n",
    "\n",
    "Then we just need to pass all of this along with our datasets to the `Trainer`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2634\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 15:10:51.074176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2634 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-ner/checkpoint-500\n",
      "Configuration saved in test-ner/checkpoint-500/config.json\n",
      "Model weights saved in test-ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to test-ner/checkpoint-1000\n",
      "Configuration saved in test-ner/checkpoint-1000/config.json\n",
      "Model weights saved in test-ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to test-ner/checkpoint-1500\n",
      "Configuration saved in test-ner/checkpoint-1500/config.json\n",
      "Model weights saved in test-ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to test-ner/checkpoint-2000\n",
      "Configuration saved in test-ner/checkpoint-2000/config.json\n",
      "Model weights saved in test-ner/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to test-ner/checkpoint-2500\n",
      "Configuration saved in test-ner/checkpoint-2500/config.json\n",
      "Model weights saved in test-ner/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2634, training_loss=0.08509582548134238, metrics={'train_runtime': 265.5655, 'train_samples_per_second': 158.616, 'train_steps_per_second': 9.918, 'total_flos': 509926772226690.0, 'train_loss': 0.08509582548134238, 'epoch': 3.0})"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of the NER model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/204 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.05975901335477829,\n 'eval_precision': 0.9282709763117113,\n 'eval_recall': 0.9381362568519969,\n 'eval_f1': 0.9331775440939187,\n 'eval_accuracy': 0.9841136193940935,\n 'eval_runtime': 5.7369,\n 'eval_samples_per_second': 566.509,\n 'eval_steps_per_second': 35.559,\n 'epoch': 3.0}"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def compute_test_results():\n",
    "    predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, pos_tags, chunk_tags, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3453\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'LOC': {'precision': 0.8968792401628223,\n  'recall': 0.9375886524822695,\n  'f1': 0.9167822468793343,\n  'number': 2115},\n 'MISC': {'precision': 0.7970863683662851,\n  'recall': 0.7621890547263681,\n  'f1': 0.7792472024415055,\n  'number': 1005},\n 'ORG': {'precision': 0.8780581039755352,\n  'recall': 0.8664654847227461,\n  'f1': 0.8722232770077842,\n  'number': 2651},\n 'PER': {'precision': 0.9721293199554069,\n  'recall': 0.9582417582417583,\n  'f1': 0.9651355838406197,\n  'number': 2730},\n 'overall_precision': 0.9036442976766128,\n 'overall_recall': 0.9013057287377956,\n 'overall_f1': 0.9024734982332157,\n 'overall_accuracy': 0.9777294385746841}"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_test_results()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving trainer state and the model for later use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "trainer.save_state()\n",
    "trainer.save_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing with custom input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "# e.g. Wings began recording sessions for its next album in London in November 1974x\n",
    "custom_sentence = \"Wings began recording sessions for its next album in London in November 1974x\" # input()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "inputs = tokenizer(custom_sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
    "inputs[\"input_ids\"] = inputs[\"input_ids\"].to(device=model.device)\n",
    "inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(device=model.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "predicted_classes = outputs['logits'].argmax(axis=2).cpu().numpy()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(ids=inputs[\"input_ids\"].cpu().numpy()[0], skip_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wings ----> B-ORG\n",
      "began ----> O\n",
      "recording ----> O\n",
      "sessions ----> O\n",
      "for ----> O\n",
      "its ----> O\n",
      "next ----> O\n",
      "album ----> O\n",
      "in ----> O\n",
      "london ----> B-LOC\n",
      "in ----> O\n",
      "november ----> O\n",
      "1974 ----> O\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(predicted_classes):\n",
    "    if tokens[i] in [tokenizer.sep_token, tokenizer.cls_token]:\n",
    "        continue\n",
    "    print(f\"{tokens[i]} ----> {label_list[p]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-lit-template",
   "language": "python",
   "display_name": "lit_template"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}